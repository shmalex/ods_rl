{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290ba2dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T01:31:39.343505Z",
     "start_time": "2022-12-04T01:31:39.331879Z"
    }
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import numpy as np\n",
    "import Frozen_Lake as fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff5c9b",
   "metadata": {},
   "source": [
    "env = fl.FrozenLakeEnv(map_name=\"4x4\")\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f941a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_all_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b2e4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_policy(env):\n",
    "\n",
    "    actions_set = set()\n",
    "\n",
    "    row_max = 0\n",
    "    col_max = 0\n",
    "    for state in env.get_all_states():\n",
    "        actions_set.update(env.get_possible_actions(state))\n",
    "        row_max = max(row_max, state[0])\n",
    "        col_max = max(col_max, state[1])\n",
    "\n",
    "    actions = {i:action for i,action in enumerate(sorted(actions_set))}\n",
    "\n",
    "    policy = np.zeros((row_max+1, col_max+1, len(actions_set)))\n",
    "\n",
    "    print('policies    |states')\n",
    "    for y,x in env.get_all_states():\n",
    "        possible_actions = env.get_possible_actions((y,x))\n",
    "        if len(possible_actions)!=0:\n",
    "            uniform_prob = 1/len(possible_actions)\n",
    "            policy[y][x] = uniform_prob\n",
    "        print(policy[y][x], y, x,)\n",
    "    return policy, list(sorted(actions_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f52e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies    |states\n",
      "[0.25 0.25 0.25 0.25] 0 0\n",
      "[0.25 0.25 0.25 0.25] 0 1\n",
      "[0.25 0.25 0.25 0.25] 0 2\n",
      "[0.25 0.25 0.25 0.25] 0 3\n",
      "[0.25 0.25 0.25 0.25] 1 0\n",
      "[0. 0. 0. 0.] 1 1\n",
      "[0.25 0.25 0.25 0.25] 1 2\n",
      "[0. 0. 0. 0.] 1 3\n",
      "[0.25 0.25 0.25 0.25] 2 0\n",
      "[0.25 0.25 0.25 0.25] 2 1\n",
      "[0.25 0.25 0.25 0.25] 2 2\n",
      "[0. 0. 0. 0.] 2 3\n",
      "[0. 0. 0. 0.] 3 0\n",
      "[0.25 0.25 0.25 0.25] 3 1\n",
      "[0.25 0.25 0.25 0.25] 3 2\n",
      "[0. 0. 0. 0.] 3 3\n"
     ]
    }
   ],
   "source": [
    "policy,actions_set = init_policy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65137004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.25, 0.25, 0.25, 0.25],\n",
       "         [0.25, 0.25, 0.25, 0.25],\n",
       "         [0.25, 0.25, 0.25, 0.25],\n",
       "         [0.25, 0.25, 0.25, 0.25]],\n",
       " \n",
       "        [[0.25, 0.25, 0.25, 0.25],\n",
       "         [0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.25, 0.25, 0.25, 0.25],\n",
       "         [0.  , 0.  , 0.  , 0.  ]],\n",
       " \n",
       "        [[0.25, 0.25, 0.25, 0.25],\n",
       "         [0.25, 0.25, 0.25, 0.25],\n",
       "         [0.25, 0.25, 0.25, 0.25],\n",
       "         [0.  , 0.  , 0.  , 0.  ]],\n",
       " \n",
       "        [[0.  , 0.  , 0.  , 0.  ],\n",
       "         [0.25, 0.25, 0.25, 0.25],\n",
       "         [0.25, 0.25, 0.25, 0.25],\n",
       "         [0.  , 0.  , 0.  , 0.  ]]]),\n",
       " ['down', 'left', 'right', 'up'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy, actions_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2cda8c",
   "metadata": {},
   "source": [
    "Policy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b918c",
   "metadata": {},
   "source": [
    "Value Function\n",
    "$$v_\\pi(s)=\\mathbb{E}_\\pi\\left[G\\right]$$\n",
    "\n",
    "\n",
    "$$v^{k+1}(s)=\\sum_{a}\\pi(a|s)\\left(\\mathcal{R}(s,a)+\\gamma\\sum_{s'}\\mathcal{P}(s'|s,a)v^k(s')\\right), s\\in{S}$$\n",
    "or\n",
    "$$v^{k+1}=\\mathcal{R}_\\pi+\\gamma\\mathcal{P}_{\\pi}v^k$$\n",
    "\n",
    "Value Function in deterministic Case: \n",
    "$$v_\\pi(s)=G(\\tau_\\pi)$$\n",
    "\n",
    "Action-Value Function\n",
    "\n",
    "$$q_{\\pi}(s,a)=\\mathbb{E}_\\pi\\left[G|S_0=s,A_0=a\\right]$$\n",
    "\n",
    "\n",
    "$$q_{\\pi}(s,a)=\\mathcal{R}(s_0,a_0)+\\mathcal{R}(s,a)+\\gamma\\sum_{s'}\\mathcal{P}(s'|s,a)v_{\\pi}(s')$$\n",
    "\n",
    "$$q_{\\pi}(s,a)=\\mathcal{R}(s,a)+\\gamma\\sum_{s'}\\left(\\mathcal{P}(s'|s,a)\\sum_{a'}\\pi(a'|s')q(_{\\pi}(s',a')\\right)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Algorithm:\n",
    "Let $\\pi^0$ - это начальный полиси and $L,K\\in\\mathbb{N}$. $%invisible$\n",
    "$%https://www.overleaf.com/learn/latex/Mathematical_fonts$\n",
    "For each $k \\in \\overline{0,K}$,do\n",
    "\n",
    "- (Policy Evaluation) Iterative Policy Evaluation\n",
    "$v^{l+1}=R_{\\pi^k}+P_{\\pi^k}v^l, l\\in\\overline{0,L-1}$\n",
    "\n",
    "Define $q^L(s,a)$ by $v^L(s)$\n",
    "\n",
    "- (Policy improvement) Greedy Policy Imporvement\n",
    "\n",
    "$$\\pi^{k+1}(a|s) = \\begin{cases}\n",
    "1, \\text{if } a \\in \\text{argmax}_{a'\\in\\mathbb{A}}q^L(s,a')\\\\\n",
    "0, \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181fadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd2afa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0, 'left': 1, 'right': 2, 'up': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_dict ={action:i for i,action in enumerate(sorted(actions_set))}\n",
    "actions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57279a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ecc3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46fe9095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_values(policy):\n",
    "     return np.zeros((policy.shape[0]*policy.shape[1],))\n",
    "values = init_values(policy)\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229691c0",
   "metadata": {},
   "source": [
    "Initial values:\n",
    "$$v^{0}=\\mathcal{R}_{\\pi^k}$$\n",
    "\n",
    "\n",
    "$$v^{l+1}=\\mathcal{R}_{\\pi^k}+\\mathcal{P}_{\\pi^k}v^l$$\n",
    "$$v^{l+2}=\\mathcal{R}_{\\pi^k}+\\mathcal{P}_{\\pi^k}v^{l+1}$$\n",
    "$$v^{l+2}=\\mathcal{R}_{\\pi^k}+\\mathcal{P}_{\\pi^k}(\\mathcal{R}_{\\pi^k}+\\mathcal{P}_{\\pi^k}v^l)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293d8b8",
   "metadata": {},
   "source": [
    "$$v^{k+1}(s)=\\sum_{a}\\pi(a|s)\\left(\\mathcal{R}(s,a)+\\gamma\\sum_{s'}\\mathcal{P}(s'|s,a)v^k(s')\\right), s\\in{S}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828790a4",
   "metadata": {},
   "source": [
    "NO: $$\\mathcal{R}(s,a)=\\sum_{s'}\\pi(s'|a,s)\\mathcal{R}(s,a,s')$$ - all possible transitions, mult by probs and sum of it\n",
    "\n",
    "$$v^{k+1}(s)=\\sum_{a}\\pi(a|s)\\left(\\sum_{s'}\\mathcal{R}(s,a,s')+\\gamma\\sum_{s'}\\mathcal{P}(s'|s,a)v^k(s')\\right), s\\in{S}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638e933",
   "metadata": {},
   "source": [
    "$$v^{k+1}(s)=\\sum_{a}\\left(\\pi(a|s)\\sum_{s'}\\mathcal{R}(s,a,s')+\\gamma\\pi(a|s)\\sum_{s'}\\mathcal{P}(s'|s,a)v^k(s')\\right), s\\in{S}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c16e2",
   "metadata": {},
   "source": [
    "$$v^{k+1}(s)=\\sum_{a}\\left(\\sum_{s'}\\pi(a|s)\\mathcal{R}(s,a,s')+\\gamma\\sum_{s'}\\pi(a|s)\\mathcal{P}(s'|s,a)v^k(s')\\right), s\\in{S}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61cd85",
   "metadata": {},
   "source": [
    "$$v^{k+1}(s)=\\sum_{a}\\left(\\sum_{s'}\\left(\\pi(a|s)\\mathcal{R}(s,a,s')+\\gamma\\pi(a|s)\\mathcal{P}(s'|s,a)v^k(s')\\right)\\right), s\\in{S}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87850cf0",
   "metadata": {},
   "source": [
    "$$v^{k+1}(s)=\\sum_{a}\\left(\\sum_{s'}\\pi(a|s)\\left(\\mathcal{R}(s,a,s')+\\gamma\\mathcal{P}(s'|s,a)v^k(s')\\right)\\right), s\\in{S}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17ac044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 (3, 2) down (3, 3) 0.1\n",
      "1.0 (3, 2) right (3, 3) 0.8\n",
      "1.0 (3, 2) up (3, 3) 0.1\n"
     ]
    }
   ],
   "source": [
    "for state in env.get_all_states():\n",
    "    for action in env.get_possible_actions(state):\n",
    "        for next_state in env.get_next_states(state, action):\n",
    "            prob = env.get_transition_prob(state, action, next_state)\n",
    "            reward = env.get_reward(state, action, next_state)\n",
    "            if reward!=0:\n",
    "                print(reward,state, action, next_state, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd9225e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92066aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation_step(policy, values, gamma):\n",
    "    new_values = np.zeros(policy.shape[0]*policy.shape[1])\n",
    "\n",
    "    # policy evaluation\n",
    "\n",
    "    for state in env.get_all_states():\n",
    "        state_y, state_x = state\n",
    "        idx_new_values = state_y*policy.shape[0] + state_x\n",
    "        for action in env.get_possible_actions(state):\n",
    "            policy_prob = policy[state_y][state_x][actions_dict[action]]\n",
    "            mean_reward =0\n",
    "\n",
    "            total_reward = 0\n",
    "            total_value = 0\n",
    "            for next_state in env.get_next_states(state, action):\n",
    "                next_state_y, next_state_x = next_state\n",
    "                idx_old_values = next_state_y*policy.shape[0] + next_state_x\n",
    "                # reward\n",
    "                reward = env.get_reward(state, action, next_state)\n",
    "                total_reward += reward\n",
    "                # value\n",
    "                trans_prob = env.get_transition_prob(state, action, next_state)\n",
    "                value_func = values[idx_old_values]\n",
    "                total_value += gamma * trans_prob * value_func\n",
    "\n",
    "            new_values[idx_new_values] += \\\n",
    "                policy_prob * (total_reward + total_value)\n",
    "\n",
    "    return new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd543da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.75, 0.  ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = policy_evaluation_step(policy, values, gamma)\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b215ca",
   "metadata": {},
   "source": [
    "$$q_{\\pi}(s,a)=\\mathcal{R}(s,a)+\\gamma\\sum_{s'}\\mathcal{P}(s'|s,a)v_\\pi(s')$$\n",
    "since we have specific environment, that give you reward for transitioning to specific satet\n",
    "$$q_{\\pi}(s,a)=\\sum_{s'}\\mathcal{R}(s',s,a)+\\gamma\\sum_{s'}\\mathcal{P}(s'|s,a)v_\\pi(s')$$\n",
    "\n",
    "$$q_{\\pi}(s,a)=\\sum_{s'}\\left(\\mathcal{R}(s',s,a)+\\gamma\\mathcal{P}(s'|s,a)v_\\pi(s')\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd7d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как опеределить дурацкий Ку\n",
    "# это матрица состояний на действия со значение награды.\n",
    "\n",
    "q = np.zeros(policy.shape) #(S,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d09a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0, 'left': 1, 'right': 2, 'up': 3}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dca2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(policy, q):\n",
    "    new_q = np.zeros(policy.shape)\n",
    "\n",
    "    for state in env.get_all_states():\n",
    "        state_y, state_x = state\n",
    "        # actions_dict[action]\n",
    "        for action in env.get_possible_actions(state):\n",
    "            for next_state in env.get_next_states(state, action):\n",
    "                next_state_y, next_state_x = state\n",
    "\n",
    "                reward = env.get_reward(state, action, next_state)\n",
    "                prob = env.get_transition_prob(state, action, next_state)\n",
    "                value = values[next_state_y*policy.shape[0]+next_state_x]\n",
    "\n",
    "                new_q[state_y][state_x][actions_dict[action]] \\\n",
    "                    = reward + gamma*prob*value\n",
    "    return new_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e5bdf",
   "metadata": {},
   "source": [
    "- (Policy improvement) Greedy Policy Imporvement\n",
    "$$\\pi^{k+1}(a|s) = \\begin{cases}\n",
    "1, \\text{if } a \\in \\text{argmax}_{a'\\in\\mathbb{A}}q^L(s,a')\\\\\n",
    "0, \\text{otherwise}\n",
    "\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf1c0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100\n",
    "K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1617747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01343178, 0.01266737, 0.03020027, 0.01235466, 0.02016588,\n",
       "       0.        , 0.07900113, 0.        , 0.05602845, 0.17282102,\n",
       "       0.32091584, 0.        , 0.        , 0.39114915, 1.17447048,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = init_values(policy)\n",
    "for k in range(K):\n",
    "    values = policy_evaluation_step(policy, values, gamma)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0f33ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shmalex/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(2, 2): 0.1, (3, 1): 0.8, (3, 2): 0.1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_next_states((3,2), 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "600bd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, 2): 0.1, (3, 3): 0.8, (2, 2): 0.1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_next_states((3,2), 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90bf538f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00120886, 0.00120886, 0.00120886, 0.01087974],\n",
       "        [0.00114006, 0.00114006, 0.00114006, 0.00114006],\n",
       "        [0.00271802, 0.00271802, 0.00271802, 0.00271802],\n",
       "        [0.00111192, 0.00111192, 0.01000727, 0.00111192]],\n",
       "\n",
       "       [[0.00181493, 0.00181493, 0.00181493, 0.00181493],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.0071101 , 0.0071101 , 0.0071101 , 0.0071101 ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.00504256, 0.00504256, 0.00504256, 0.00504256],\n",
       "        [0.01555389, 0.01555389, 0.01555389, 0.01555389],\n",
       "        [0.02888243, 0.02888243, 0.02888243, 0.02888243],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.03520342, 0.03520342, 0.03520342, 0.03520342],\n",
       "        [1.10570234, 0.10570234, 0.10570234, 0.10570234],\n",
       "        [0.        , 0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Q(policy, q)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e95d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down', 'left', 'right', 'up']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4b0d3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_imporvement(policy, q):\n",
    "    next_policy = np.zeros(policy.shape)\n",
    "    for state in env.get_all_states():\n",
    "        state_y,state_x = state\n",
    "\n",
    "        idx_action = np.argmax(q[state_y][state_x])\n",
    "        next_policy[state_y][state_x][idx_action] = 1\n",
    "    return next_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aab6cc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0, 'left': 1, 'right': 2, 'up': 3}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "731538fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100\n",
    "K = 100\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f785765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies    |states\n",
      "[0.25 0.25 0.25 0.25] 0 0\n",
      "[0.25 0.25 0.25 0.25] 0 1\n",
      "[0.25 0.25 0.25 0.25] 0 2\n",
      "[0.25 0.25 0.25 0.25] 0 3\n",
      "[0.25 0.25 0.25 0.25] 1 0\n",
      "[0. 0. 0. 0.] 1 1\n",
      "[0.25 0.25 0.25 0.25] 1 2\n",
      "[0. 0. 0. 0.] 1 3\n",
      "[0.25 0.25 0.25 0.25] 2 0\n",
      "[0.25 0.25 0.25 0.25] 2 1\n",
      "[0.25 0.25 0.25 0.25] 2 2\n",
      "[0. 0. 0. 0.] 2 3\n",
      "[0. 0. 0. 0.] 3 0\n",
      "[0.25 0.25 0.25 0.25] 3 1\n",
      "[0.25 0.25 0.25 0.25] 3 2\n",
      "[0. 0. 0. 0.] 3 3\n"
     ]
    }
   ],
   "source": [
    "policy, actions = init_policy(env)\n",
    "values = init_values(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5593116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "51f9a5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = init_values(policy)\n",
    "for k in range(K):\n",
    "    values = policy_evaluation_step(policy, values, gamma)\n",
    "    q = np.zeros(policy.shape)\n",
    "    q = Q(policy, q)\n",
    "    policy = policy_imporvement(policy, q)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8c65c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08af87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_counter = Counter()\n",
    "for state in env.get_all_states():\n",
    "    actions = env.get_possible_actions(state)\n",
    "    actions_counter.update(['-'.join(actions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b923d8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'left-down-right-up': 11, '': 5})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8925d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shmalex/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25]],\n",
       "\n",
       "       [[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.  , 0.  , 0.  , 0.  ]],\n",
       "\n",
       "       [[0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.  , 0.  , 0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25],\n",
       "        [0.  , 0.  , 0.  , 0.  ]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7961a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down', 'left', 'right', 'up']\n",
      "(0, 0) 0.0 False {} up [0. 0. 0. 1.]\n",
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "['down', 'left', 'right', 'up']\n",
      "(0, 0) 0.0 False {} up [0. 0. 0. 1.]\n",
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "['down', 'left', 'right', 'up']\n",
      "(0, 0) 0.0 False {} up [0. 0. 0. 1.]\n",
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "['down', 'left', 'right', 'up']\n",
      "(0, 0) 0.0 False {} up [0. 0. 0. 1.]\n",
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "['down', 'left', 'right', 'up']\n",
      "(0, 1) 0.0 False {} up [0. 0. 0. 1.]\n",
      "S*FF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "['down', 'left', 'right', 'up']\n",
      "(1, 1) 0.0 True {} down [1. 0. 0. 0.]\n",
      "SFFF\n",
      "F*FH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_reward = 0\n",
    "state = env.reset()\n",
    "for _ in range(100):\n",
    "    possible_actions = list(sorted(env.get_possible_actions(state)))\n",
    "    print(possible_actions)\n",
    "    state_y, state_x = state\n",
    "    actions_distr = policy[state_y][state_x]\n",
    "    \n",
    "    action = np.random.choice(possible_actions,p=actions_distr)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    print(state, reward, done, _,action, actions_distr)\n",
    "    env.render()\n",
    "    total_reward += reward\n",
    "    \n",
    "    if done: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad0596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f278d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c60c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0ca8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beee14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1680ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34584611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b93e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c36d240d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fa687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
